{
    "domain": "visual_reasoning",
    "version": "v1.1",
    "description": "Claim schemas for probing visual reasoning capabilities across entity grounding, spatial reasoning, scale estimation, counting, absence detection, occlusion handling, orientation, geographic recognition, and image-text alignment. Baseline model selects optimal instantiation targets from image content.",
    "enabled_claim_ids": [
      "entity_basic_grounding",
      "concept_single_object",
      "spatial_absolute_position",
      "spatial_relative_position",
      "scale_proportion_estimation",
      "counting_object_instances",
      "absence_negative_reasoning",
      "orientation_facing_direction"
    ],
    "enabled_claim_names": [
      "Basic Visual Entity Grounding",
      "Single Object Abstract Concept Extraction",
      "Absolute Position Recognition",
      "Relative Spatial Relationship",
      "Scale and Proportion Estimation",
      "Object Instance Counting",
      "Object Absence Detection",
      "Object Orientation Recognition"
    ],
    
    "slot_type_definitions": {
      "object_instance": "A specific, visually identifiable object in the image selected by the baseline model",
      "object_category": "A semantic category name for countable or recognizable objects",
      "abstract_concept": "A non-visual, category-level or system-level concept inferred from visual elements",
      "categorical_value": "A value from a predefined set of options",
      "integer_value": "An exact integer count or numeric value",
      "spatial_descriptor": "A description of a spatial region or position in the image",
      "natural_language_text": "Free-form natural language description generated from visual content"
    },
  
    "claim_schemas": [
      {
        "claim_id": "entity_basic_grounding",
        "name": "Basic Visual Entity Grounding",
        "capability": "visual_entity_recognition",
        "target_failure_id": "FR_BASIC_VISUAL_ENTITY_GROUNDING_FAILURE",
        "claim_template": "The image contains [ENTITY_TYPE] as a visually identifiable element.",
        "slots": {
          "ENTITY_TYPE": {
            "type": "object_instance",
            "selection_criteria": "Select the most visually salient and clearly identifiable entity, structure, or object in the image"
          }
        },
        "baseline_instructions": [
          "Scan the image for visually identifiable entities (objects, symbols, diagrams, scene elements).",
          "Select the most salient entity with clear visual boundaries or distinguishable features.",
          "If the image contains only noise, uninterpretable patterns, or no discernible entities, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image contains only texture, noise, or abstract patterns without identifiable entities",
          "No entity has distinguishable boundaries or recognizable features",
          "Visual content is too degraded or ambiguous to identify any specific element"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "missing entities",
          "overly generic descriptions",
          "incorrect denial of entity presence",
          "failure to distinguish entities from background"
        ]
      },
      {
        "claim_id": "concept_single_object",
        "name": "Single Object Abstract Concept Extraction",
        "capability": "object_level_conceptual_abstraction",
        "target_failure_id": "FR_OBJECT_LEVEL_ABSTRACT_CONCEPT_MISSING",
        "claim_template": "The [OBJECT_INSTANCE] in the image belongs to the category [ABSTRACT_CATEGORY] and has the property [PROPERTY].",
        "slots": {
          "OBJECT_INSTANCE": {
            "type": "object_instance",
            "selection_criteria": "Select the most prominent single object that has well-defined categorical properties"
          },
          "ABSTRACT_CATEGORY": {
            "type": "abstract_concept",
            "selection_criteria": "Infer a non-visual, category-level classification (e.g., biological taxonomy, functional class)"
          },
          "PROPERTY": {
            "type": "abstract_concept",
            "selection_criteria": "Infer a stable, category-level property from common knowledge (not instance-specific visual features)"
          }
        },
        "prefill_slots": ["OBJECT_INSTANCE"],
        "baseline_instructions": [
          "Identify the most prominent single object with clear categorical identity.",
          "Infer its abstract category and a stable, non-visual property from common knowledge.",
          "If multiple objects dominate, instance identity is ambiguous, or no category-level properties apply, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No single dominant object exists (multiple equally prominent objects)",
          "Object has no well-defined category or taxonomy in common knowledge",
          "Only instance-specific visual properties are available, no stable category-level properties"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "confusing visual features with abstract properties",
          "inability to infer category-level knowledge",
          "providing instance-specific rather than category-level properties"
        ]
      },
      {
        "claim_id": "concept_multi_object_system",
        "name": "Multi-Object System Concept Abstraction",
        "capability": "system_level_conceptual_abstraction",
        "target_failure_id": "FR_MULTI_OBJECT_CONCEPT_ABSTRACTION_FAILURE",
        "claim_template": "The relationships between elements in the image represent the concept of [SYSTEM_CONCEPT].",
        "slots": {
          "SYSTEM_CONCEPT": {
            "type": "abstract_concept",
            "selection_criteria": "Infer the most salient process, system, or mechanistic concept implied by relationships between elements (e.g., 'water cycle', 'food chain', 'circuit flow')"
          }
        },
        "baseline_instructions": [
          "Examine whether multiple entities have relationships.",
          "Infer the higher-level systemic or process-oriented concept these relationships represent.",
          "If entities are unrelated, no structured relationships exist, or only element-level descriptions are possible, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image contains only isolated entities with no structured relationships",
          "No higher-level system or process concept can be inferred from visual relationships",
          "Relationships are purely spatial proximity without functional or process meaning"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "recognizing individual entities but missing the systemic concept",
          "providing element-level descriptions instead of process-level abstraction",
          "inability to infer conventional diagrammatic representations"
        ]
      },
      {
        "claim_id": "spatial_absolute_position",
        "name": "Absolute Position Recognition",
        "capability": "absolute_spatial_localization",
        "target_failure_id": "FR_ABSOLUTE_POSITION_ERROR",
        "claim_template": "The [TARGET_OBJECT] is located in the [ABSOLUTE_REGION] of the image.",
        "slots": {
          "TARGET_OBJECT": {
            "type": "object_instance",
            "selection_criteria": "Select the most salient object with clear visual boundaries suitable for position description"
          },
          "ABSOLUTE_REGION": {
            "type": "categorical_value",
            "values": ["top", "bottom", "left", "right", "center", "top-left", "top-right", "bottom-left", "bottom-right"],
            "selection_criteria": "Determine the absolute region based on the selected object's position"
          }
        },
        "prefill_slots": ["TARGET_OBJECT"],
        "baseline_instructions": [
          "Identify the most salient object with clear boundaries and unambiguous position.",
          "Determine its absolute position using directional terms.",
          "If no clear object exists, all objects are centrally located, or boundaries are too ambiguous, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No visually salient object with identifiable boundaries exists",
          "All potential objects are located in the center or span multiple regions ambiguously",
          "Image composition makes absolute position description meaningless (e.g., abstract art, uniform patterns)"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "left-right confusion",
          "top-bottom confusion",
          "misjudging boundary regions",
          "confusing similar objects in different positions"
        ]
      },
      {
        "claim_id": "spatial_relative_position",
        "name": "Relative Spatial Relationship",
        "capability": "relative_spatial_reasoning",
        "target_failure_id": "FR_RELATIVE_POSITION_ERROR",
        "claim_template": "The [OBJECT_A] is [RELATIVE_DIRECTION] the [OBJECT_B].",
        "slots": {
          "OBJECT_A": {
            "type": "object_instance",
            "selection_criteria": "Select a visually salient object from the image as the reference object"
          },
          "OBJECT_B": {
            "type": "object_instance",
            "selection_criteria": "Select a second visually salient object from a different semantic category than OBJECT_A"
          },
          "RELATIVE_DIRECTION": {
            "type": "categorical_value",
            "values": ["to the left of", "to the right of", "above", "below", "in front of", "behind"],
            "selection_criteria": "Determine the spatial relationship from OBJECT_A to OBJECT_B"
          }
        },
        "prefill_slots": ["OBJECT_A", "OBJECT_B"],
        "baseline_instructions": [
          "Identify at least two visually salient objects from different semantic categories.",
          "Determine their relative spatial relationship using directional terms.",
          "If fewer than two distinct objects exist, objects are from the same category, or spatial relationship is ambiguous, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Fewer than two distinguishable objects exist in the image",
          "All objects belong to the same semantic category (no meaningful distinction)",
          "Objects overlap completely or spatial relationship is too ambiguous to describe",
          "Image contains only a single uniform element or scattered identical items"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "left-right reversal",
          "confusing overlapping objects",
          "misjudging depth relationships",
          "distractor object confusion"
        ]
      },
      {
        "claim_id": "scale_proportion_estimation",
        "name": "Scale and Proportion Estimation",
        "capability": "relative_size_estimation",
        "target_failure_id": "FR_SCALE_PROPORTION_ERROR",
        "claim_template": "The [TARGET_OBJECT] occupies approximately [PROPORTION] of the image area.",
        "slots": {
          "TARGET_OBJECT": {
            "type": "object_instance",
            "selection_criteria": "Select the most salient object with discernible boundaries suitable for proportion estimation"
          },
          "PROPORTION": {
            "type": "categorical_value",
            "values": ["less than 10%", "10-25%", "25-50%", "50-75%", "more than 75%"],
            "selection_criteria": "Estimate the proportion of total image area occupied by the object"
          }
        },
        "prefill_slots": ["TARGET_OBJECT"],
        "baseline_instructions": [
          "Identify the most salient object with clear, discernible boundaries.",
          "Estimate the approximate proportion of image area it occupies.",
          "If no object has clear boundaries, the object spans the entire image uniformly, or boundaries are indiscernible, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No object with discernible boundaries exists",
          "Image is filled with uniform texture or pattern (no distinct object to measure)",
          "Object boundaries are too ambiguous to allow proportion estimation"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "overestimating small objects",
          "underestimating large objects",
          "confusion with partial occlusion",
          "difficulty with complex arrangements"
        ]
      },
      {
        "claim_id": "counting_object_instances",
        "name": "Object Instance Counting",
        "capability": "discrete_object_counting",
        "target_failure_id": "FR_OBJECT_COUNTING_CONFUSION",
        "claim_template": "There are exactly [COUNT] instances of [OBJECT_TYPE] visible in the image.",
        "slots": {
          "OBJECT_TYPE": {
            "type": "object_category",
            "selection_criteria": "Select the single most salient object category that is clearly countable, allowing the number of instances to be zero, one, or more."
          },
          "COUNT": {
            "type": "integer_value",
            "selection_criteria": "Count all visible instances, including partially visible ones, of the selected object type"
          }
        },
        "prefill_slots": ["OBJECT_TYPE"],
        "baseline_instructions": [
          "Identify the most salient countable object category (should have discrete, identifiable instances).",
          "Count all visible instances of that category, including partially visible ones.",
          "If no countable object category exists, instances are completely indistinguishable, or counting is meaningless (e.g., uncountable substances), return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No countable object category exists (only amorphous substances, textures, or continuous elements)",
          "Object instances are completely indistinguishable from each other (no boundaries)",
          "Image is too degraded, blurred, or occluded to allow any instance counting"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "undercounting due to occlusion",
          "overcounting due to reflections or shadows",
          "confusion between similar object subtypes",
          "missing partially visible instances",
          "counting zero when objects are present"
        ]
      },
      {
        "claim_id": "absence_negative_reasoning",
        "name": "Object Absence Detection",
        "capability": "negative_spatial_reasoning",
        "target_failure_id": "FR_ABSENCE_REASONING_FAILURE",
        "claim_template": "The [REGION_DESCRIPTION] region contains no [OBJECT_TYPE].",
        "slots": {
          "REGION_DESCRIPTION": {
            "type": "spatial_descriptor",
            "selection_criteria": "Select a clearly distinguishable spatial region in the image (e.g., 'left half', 'upper portion', 'upper-right')"
          },
          "OBJECT_TYPE": {
            "type": "object_category",
            "selection_criteria": "Select a salient object category present elsewhere in the image or plausibly expected in the scene"
          }
        },
        "prefill_slots": ["OBJECT_TYPE"],
        "baseline_instructions": [
          "Identify at least one salient object category present in the image or expected in the scene context.",
          "Identify a clearly distinguishable spatial region that is devoid of that object type.",
          "If no clear empty regions exist, objects are uniformly distributed across the image, or no spatial boundaries are distinguishable, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Objects are uniformly distributed across the entire image with no empty regions",
          "No clear spatial regions can be distinguished in the image",
          "No salient object category exists to reason about absence",
          "Image is too cluttered or ambiguous to identify empty regions"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "overlooking empty regions",
          "false positive detection in empty areas",
          "vague answers for unoccupied regions",
          "confusion with background blending objects"
        ]
      },
      {
        "claim_id": "occlusion_robustness",
        "name": "Partially Occluded Object Recognition",
        "capability": "partial_visibility_handling",
        "target_failure_id": "FR_OCCLUSION_SENSITIVITY",
        "claim_template": "The partially visible object in the image is identifiable as a [OBJECT_IDENTITY].",
        "slots": {
          "OBJECT_IDENTITY": {
            "type": "object_category",
            "selection_criteria": "Select the most salient partially occluded object that retains sufficient visual cues for identification"
          }
        },
        "baseline_instructions": [
          "Identify objects that are partially occluded, truncated, or only partially visible.",
          "Select the most salient partially visible object that still retains sufficient visual cues for recognition.",
          "If all objects are fully visible, all objects are too heavily occluded to identify, or no partial occlusion exists, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "All objects in the image are fully visible with no occlusion",
          "All partially visible objects are too heavily occluded to retain any recognizable features",
          "No objects with partial visibility exist in the image"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "refusing to identify partially visible objects",
          "misidentifying occluded objects",
          "ignoring valid partial objects",
          "over-reliance on complete visibility"
        ]
      },
      {
        "claim_id": "orientation_facing_direction",
        "name": "Object Orientation Recognition",
        "capability": "directional_orientation_reasoning",
        "target_failure_id": "FR_OBJECT_ORIENTATION_ERROR",
        "claim_template": "The [OBJECT] is facing [DIRECTION].",
        "slots": {
          "OBJECT": {
            "type": "object_instance",
            "selection_criteria": "Select the most salient object that has an inherent facing direction (e.g., animals, vehicles, people, arrows)"
          },
          "DIRECTION": {
            "type": "categorical_value",
            "values": ["left", "right", "toward viewer", "away from viewer", "upward", "downward"],
            "selection_criteria": "Determine the facing direction of the selected object"
          }
        },
        "prefill_slots": ["OBJECT"],
        "baseline_instructions": [
          "Identify the most salient object that has an inherent facing or pointing direction.",
          "Determine its orientation using directional terms.",
          "If only orientation-neutral objects exist (e.g., spheres, boxes with no discernible front), or orientation is completely ambiguous, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "All objects in the image are orientation-neutral (no inherent facing direction)",
          "Object orientation is completely ambiguous or cannot be determined from visible cues",
          "No objects with directional properties exist in the image"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "left-right confusion",
          "difficulty with small or occluded objects",
          "confusion with overlapping objects",
          "failure in fine-grained directional discrimination"
        ]
      },
      {
        "claim_id": "geographic_place_recognition",
        "name": "Geographic Location Identification",
        "capability": "map_based_place_recognition",
        "target_failure_id": "FR_PLACE_RECOGNITION_ERROR",
        "claim_template": "The highlighted region in the map represents [GEOGRAPHIC_LOCATION].",
        "slots": {
          "GEOGRAPHIC_LOCATION": {
            "type": "abstract_concept",
            "selection_criteria": "Infer the real-world geographic location (country, state, region, city) from the highlighted region and surrounding map context"
          }
        },
        "baseline_instructions": [
          "Determine if the image is a geographic map with a visually highlighted or distinguished region.",
          "Use shape, surrounding context, and any visual cues to infer the geographic location.",
          "If not a map, no highlighted region exists, or insufficient geographic cues are available for identification, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image is not a geographic map representation",
          "No region is visually highlighted or distinguished from the background",
          "Insufficient geographic cues exist to support location inference (too abstract or schematic)",
          "Map is purely fictional or non-geographic"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "misidentifying similar-shaped regions",
          "requiring external knowledge beyond visual cues",
          "confusion due to map distortion",
          "failure with minimal textual labels"
        ]
      },
      {
        "claim_id": "image_text_alignment",
        "name": "Image-to-Text Description Alignment",
        "capability": "visual_content_captioning",
        "target_failure_id": "FR_BASIC_IMAGE_TEXT_ALIGNMENT",
        "claim_template": "The image depicts [SCENE_DESCRIPTION].",
        "slots": {
          "SCENE_DESCRIPTION": {
            "type": "natural_language_text",
            "selection_criteria": "Generate a natural language description capturing the main visually perceivable content (objects, scenes, activities, or compositions)"
          }
        },
        "baseline_instructions": [
          "Generate a description that accurately reflects the main visually perceivable content in the image.",
          "Focus on objects, scenes, activities, or compositional elements that are directly observable.",
          "If the image is severely degraded, purely abstract with no recognizable content, or contains only noise, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image is severely degraded, too blurry, or noisy to discern any content",
          "Image is purely abstract with no recognizable objects, scenes, or activities",
          "No visually perceivable content exists to describe"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "omitting visible objects or activities",
          "misrepresenting scene content",
          "relying on external context not in the image",
          "overly generic or hallucinated descriptions"
        ]
      }
    ],
  
    "global_guidelines": {
      "slot_instantiation_principle": "The baseline model independently selects the most appropriate and salient elements from the image for each slot based on the selection_criteria. The goal is to maximize claim relevance and testability.",
      "not_related_usage": "Return NOT_RELATED only when the image fundamentally lacks the necessary visual properties to instantiate a meaningful claim for the given schema. This ensures claims are only generated when they can be meaningfully evaluated.",
      "integer_values": "All COUNT or numeric slots must return exact integer values, not ranges or approximations.",
      "evaluation_principle": "Claims should be evaluable as TRUE or FALSE based solely on visual content, without requiring external context beyond common knowledge."
    }
  }