{
    "domain": "visual_reasoning",
    "version": "v1.1",
    "description": "Claim schemas for probing visual reasoning capabilities across entity grounding, spatial reasoning, scale estimation, counting, absence detection, occlusion handling, orientation, geographic recognition, and image-text alignment. Baseline model selects optimal instantiation targets from image content.",
    "enabled_claim_ids": [
      "entity_basic_grounding",
      "spatial_absolute_position",
      "spatial_relative_position",
      "scale_proportion_estimation",
      "counting_object_instances",
      "absence_negative_reasoning",
      "orientation_facing_direction",
      "intra_class_single_instance_localization"
    ],
    "enabled_claim_names": [
      "Basic Visual Entity Grounding",
      "Absolute Position Recognition",
      "Relative Spatial Relationship",
      "Scale and Proportion Estimation",
      "Object Instance Counting",
      "Object Absence Detection",
      "Object Orientation Recognition",
      "Intra-class Single-instance Disambiguation and Relative Localization"
    ],
    
    "slot_type_definitions": {
      "object_instance": "A specific, visually identifiable object in the image selected by the baseline model",
      "object_category": "A semantic category name for countable or recognizable objects",
      "abstract_concept": "A non-visual, category-level or system-level concept inferred from visual elements",
      "categorical_value": "A value from a predefined set of options",
      "percentage_value": "A numeric percentage value in the range 0–100%, e.g. '35%' (optionally with one decimal place)",
      "integer_value": "An exact integer count or numeric value",
      "spatial_descriptor": "A description of a spatial region or position in the image",
      "natural_language_text": "Free-form natural language description generated from visual content",
      "instance_level_visual_feature": "A visually observable characteristic that distinguishes one or a small subset of instances within the same object category",
      "relative_spatial_relation": "A description of an object's position relative to other instances of the same category, expressed using ordinal, comparative, or group-relative spatial relations"
    },
  
    "claim_schemas": [
      {
        "claim_id": "entity_basic_grounding",
        "name": "Basic Visual Entity Grounding",
        "capability": "visual_entity_recognition",
        "target_failure_id": "FR_BASIC_VISUAL_ENTITY_GROUNDING_FAILURE",
        "claim_template": "The image contains [ENTITY_TYPE] as a visually identifiable element.",
        "slots": {
          "ENTITY_TYPE": {
            "type": "object_instance",
            "selection_criteria": "Select the most visually salient and clearly identifiable entity, structure, or object in the image"
          }
        },
        "baseline_instructions": [
          "Scan the image for visually identifiable entities (objects, symbols, diagrams, scene elements).",
          "Select the most salient entity with clear visual boundaries or distinguishable features.",
          "If the image contains only noise, uninterpretable patterns, or no discernible entities, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image contains only texture, noise, or abstract patterns without identifiable entities",
          "No entity has distinguishable boundaries or recognizable features",
          "Visual content is too degraded or ambiguous to identify any specific element"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "missing entities",
          "overly generic descriptions",
          "incorrect denial of entity presence",
          "failure to distinguish entities from background"
        ]
      },
      {
        "claim_id": "concept_single_object",
        "name": "Single Object Abstract Concept Extraction",
        "capability": "object_level_conceptual_abstraction",
        "target_failure_id": "FR_OBJECT_LEVEL_ABSTRACT_CONCEPT_MISSING",
        "claim_template": "The [OBJECT_INSTANCE] in the image belongs to the category [ABSTRACT_CATEGORY] and has the property [PROPERTY].",
        "slots": {
          "OBJECT_INSTANCE": {
            "type": "object_instance",
            "selection_criteria": "Select the most prominent single object that has well-defined categorical properties"
          },
          "ABSTRACT_CATEGORY": {
            "type": "abstract_concept",
            "selection_criteria": "Infer a non-visual, category-level classification (e.g., biological taxonomy, functional class)"
          },
          "PROPERTY": {
            "type": "abstract_concept",
            "selection_criteria": "Infer a stable, category-level property from common knowledge (not instance-specific visual features)"
          }
        },
        "prefill_slots": ["OBJECT_INSTANCE"],
        "baseline_instructions": [
          "Identify the most prominent single object with clear categorical identity.",
          "Infer its abstract category and a stable, non-visual property from common knowledge.",
          "If multiple objects dominate, instance identity is ambiguous, or no category-level properties apply, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No single dominant object exists (multiple equally prominent objects)",
          "Object has no well-defined category or taxonomy in common knowledge",
          "Only instance-specific visual properties are available, no stable category-level properties"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "confusing visual features with abstract properties",
          "inability to infer category-level knowledge",
          "providing instance-specific rather than category-level properties"
        ]
      },
      {
        "claim_id": "concept_multi_object_system",
        "name": "Multi-Object System Concept Abstraction",
        "capability": "system_level_conceptual_abstraction",
        "target_failure_id": "FR_MULTI_OBJECT_CONCEPT_ABSTRACTION_FAILURE",
        "claim_template": "The relationships between elements in the image represent the concept of [SYSTEM_CONCEPT].",
        "slots": {
          "SYSTEM_CONCEPT": {
            "type": "abstract_concept",
            "selection_criteria": "Infer the most salient process, system, or mechanistic concept implied by relationships between elements (e.g., 'water cycle', 'food chain', 'circuit flow')"
          }
        },
        "baseline_instructions": [
          "Examine whether multiple entities have relationships.",
          "Infer the higher-level systemic or process-oriented concept these relationships represent.",
          "If entities are unrelated, no structured relationships exist, or only element-level descriptions are possible, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image contains only isolated entities with no structured relationships",
          "No higher-level system or process concept can be inferred from visual relationships",
          "Relationships are purely spatial proximity without functional or process meaning"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "recognizing individual entities but missing the systemic concept",
          "providing element-level descriptions instead of process-level abstraction",
          "inability to infer conventional diagrammatic representations"
        ]
      },
      {
        "claim_id": "spatial_absolute_position",
        "name": "Absolute Position Recognition",
        "capability": "absolute_spatial_localization",
        "target_failure_id": "FR_ABSOLUTE_POSITION_ERROR",
        "claim_template": "The [TARGET_OBJECT] is located in the [ABSOLUTE_REGION] of the image.",
        "slots": {
          "TARGET_OBJECT": {
            "type": "object_instance",
            "selection_criteria": "Select the most salient object with clear visual boundaries suitable for position description"
          },
          "ABSOLUTE_REGION": {
            "type": "categorical_value",
            "values": ["top", "bottom", "left", "right", "center", "top-left", "top-right", "bottom-left", "bottom-right"],
            "selection_criteria": "Determine the absolute region based on the selected object's position"
          }
        },
        "prefill_slots": ["TARGET_OBJECT"],
        "baseline_instructions": [
          "Identify the most salient object with clear boundaries and unambiguous position.",
          "Determine its absolute position using directional terms.",
          "If no clear object exists, all objects are centrally located, or boundaries are too ambiguous, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No visually salient object with identifiable boundaries exists",
          "All potential objects are located in the center or span multiple regions ambiguously",
          "Image composition makes absolute position description meaningless (e.g., abstract art, uniform patterns)"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "left-right confusion",
          "top-bottom confusion",
          "misjudging boundary regions",
          "confusing similar objects in different positions"
        ]
      },
      {
        "claim_id": "intra_class_single_instance_localization",
        "name": "Intra-class Single-instance Disambiguation and Relative Localization",
        "capability": "intra_class_instance_grounding_and_relative_positioning",
        "target_failure_id": "FR_INTRA_CLASS_INSTANCE_POSITIONING_FAILURE",
        "claim_template": "Among the [OBJECT_CATEGORY] in the image, the one with the characteristic [DISTINCTIVE_FEATURE] is located at [RELATIVE_POSITION] compared to the others.",
        "slots": {
          "OBJECT_CATEGORY": {
            "type": "object_category",
            "selection_criteria": "Select an object category for which more than one instance appears in the image; categories with moderate visual similarity among instances are preferred but not required"
          },
          "DISTINCTIVE_FEATURE": {
            "type": "instance_level_visual_feature",
            "selection_criteria": "Prefer a non-positional visual characteristic that uniquely identifies a single instance within the category; if no such feature exists, select a non-positional characteristic that identifies the smallest possible subset of instances; the feature must not be shared by all instances and must not rely on spatial location or relative position"
          },
          "RELATIVE_POSITION": {
            "type": "relative_spatial_relation",
            "selection_criteria": "Describe the spatial position of the target instance relative to other instances of the same category (e.g., ordinal order, extremal position, or group-relative location)"
          }
        },
        "prefill_slots": ["OBJECT_CATEGORY", "DISTINCTIVE_FEATURE"],
        "baseline_instructions": [
          "Identify an object category with multiple visible instances in the image.",
          "Use the prefilled distinctive feature to locate a single target instance whenever possible.",
          "Only if unique identification is impossible, interpret the feature as referring to the smallest identifiable subset of instances.",
          "Determine the relative position of the target instance (or subset) with respect to other instances of the same category.",
          "If neither unique nor minimal-subset identification is possible, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Only a single instance of the object category is present",
          "The distinctive feature applies to all instances",
          "Multiple candidate instances remain indistinguishable after applying the feature",
          "Relative position among instances cannot be determined (e.g., severe occlusion or undefined ordering)"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "defaulting to multi-instance features when a unique feature exists",
          "treating a non-unique feature as if it referred to a single instance",
          "using absolute image coordinates instead of intra-class relative position",
          "incorrect ordinal reasoning among similar objects"
        ]
      },      
      {
        "claim_id": "spatial_relative_position",
        "name": "Relative Spatial Relationship",
        "capability": "relative_spatial_reasoning",
        "target_failure_id": "FR_RELATIVE_POSITION_ERROR",
        "claim_template": "The [OBJECT_A] is [RELATIVE_DIRECTION] the [OBJECT_B].",
        "slots": {
          "OBJECT_A": {
            "type": "object_instance",
            "selection_criteria": "Select a visually salient object from the image as the reference object"
          },
          "OBJECT_B": {
            "type": "object_instance",
            "selection_criteria": "Select a second visually salient object from a different semantic category than OBJECT_A"
          },
          "RELATIVE_DIRECTION": {
            "type": "categorical_value",
            "values": ["to the left of", "to the right of", "above", "below", "in front of", "behind"],
            "selection_criteria": "Determine the spatial relationship from OBJECT_A to OBJECT_B"
          }
        },
        "prefill_slots": ["OBJECT_A", "OBJECT_B"],
        "baseline_instructions": [
          "Identify at least two visually salient objects from different semantic categories.",
          "Determine their relative spatial relationship using directional terms.",
          "If fewer than two distinct objects exist, objects are from the same category, or spatial relationship is ambiguous, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Fewer than two distinguishable objects exist in the image",
          "All objects belong to the same semantic category (no meaningful distinction)",
          "Objects overlap completely or spatial relationship is too ambiguous to describe",
          "Image contains only a single uniform element or scattered identical items"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "left-right reversal",
          "confusing overlapping objects",
          "misjudging depth relationships",
          "distractor object confusion"
        ]
      },
      {
        "claim_id": "scale_proportion_estimation",
        "name": "Scale and Proportion Estimation",
        "capability": "relative_size_estimation",
        "target_failure_id": "FR_SCALE_PROPORTION_ERROR",
        "claim_template": "The [TARGET_OBJECT] occupies approximately [PROPORTION] of the image area.",
        "slots": {
          "TARGET_OBJECT": {
            "type": "object_instance",
            "selection_criteria": "Select the most salient object with discernible boundaries suitable for proportion estimation"
          },
          "PROPORTION": {
            "type": "percentage_value",
            "selection_criteria": "Estimate the proportion of total image area occupied by the object. Return a numeric percentage like '12%' or '37.5%' (0–100%). Do not choose from fixed buckets."
          }
        },
        "prefill_slots": ["TARGET_OBJECT"],
        "baseline_instructions": [
          "Identify the most salient object with clear, discernible boundaries.",
          "Estimate the approximate proportion of image area it occupies as a numeric percentage (0–100%), e.g., '12%'.",
          "If no object has clear boundaries, the object spans the entire image uniformly, or boundaries are indiscernible, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No object with discernible boundaries exists",
          "Image is filled with uniform texture or pattern (no distinct object to measure)",
          "Object boundaries are too ambiguous to allow proportion estimation"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "overestimating small objects",
          "underestimating large objects",
          "confusion with partial occlusion",
          "difficulty with complex arrangements"
        ]
      },
      {
        "claim_id": "counting_object_instances",
        "name": "Object Instance Counting",
        "capability": "discrete_object_counting",
        "target_failure_id": "FR_OBJECT_COUNTING_CONFUSION",
        "claim_template": "There are exactly [COUNT] instances of [OBJECT_TYPE] visible in the image.",
        "slots": {
          "OBJECT_TYPE": {
            "type": "object_category",
            "selection_criteria": "Select the single most salient object category that is clearly and unambiguously describable in language, whose instances in the image are countable without ambiguity. The category may have zero, one, or multiple instances, but must not appear in large numbers or dense distributions that make counting or reference subjective."
          },
          "COUNT": {
            "type": "integer_value",
            "selection_criteria": "Count all visible instances, including partially visible ones, of the selected object type"
          }
        },
        "prefill_slots": ["OBJECT_TYPE"],
        "baseline_instructions": [
          "Identify the most salient countable object category (should have discrete, identifiable instances).",
          "Count all visible instances of that category, including partially visible ones.",
          "If no countable object category exists, instances are completely indistinguishable, or counting is meaningless (e.g., uncountable substances), return NOT_RELATED."
        ],
        "not_related_conditions": [
          "No countable object category exists (only amorphous substances, textures, or continuous elements)",
          "Object instances are completely indistinguishable from each other (no boundaries)",
          "Image is too degraded, blurred, or occluded to allow any instance counting",
          "Target category appears in large numbers or dense arrangements (e.g., forming a background or repeated pattern), such that individual instances cannot be reliably distinguished or counted."
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "undercounting due to occlusion",
          "overcounting due to reflections or shadows",
          "confusion between similar object subtypes",
          "missing partially visible instances",
          "counting zero when objects are present"
        ]
      },
      {
        "claim_id": "absence_negative_reasoning",
        "name": "Object Absence Detection",
        "capability": "negative_spatial_reasoning",
        "target_failure_id": "FR_ABSENCE_REASONING_FAILURE",
        "claim_template": "The [REGION_DESCRIPTION] region shows no visible instances of [OBJECT_TYPE].",
        "slots": {
          "REGION_DESCRIPTION": {
            "type": "spatial_descriptor",
            "selection_criteria": "Select a clearly distinguishable spatial region that is visually identifiable as an empty or low-occupancy area."
          },
          "OBJECT_TYPE": {
            "type": "object_category",
            "selection_criteria": "Select a salient object category that is clearly visible elsewhere in the image or strongly expected in the scene context, such that its absence in a region would be visually noticeable."
          }
        },
        "prefill_slots": ["OBJECT_TYPE"],
        "baseline_instructions": [
          "Identify a spatial region that shows clear visual evidence of target object absence.",
          "Do not rely on subjective inference or arbitrary spatial partition when selecting the region; the object absence must be visually supported."
        ],
        "not_related_conditions": [
          "The target object does not occupy a significant large portion of the image, so a large region or multiple regions could be interpreted as object-absent.",
          "There exist multiple regions in the image without the target object, so the absence cannot be represented by a single region.",
          "No clearly object-absent region can be identified in the image.",
          "The target object is not clearly visible elsewhere in the image or is not noticeable."
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "overlooking visually empty regions",
          "false positive detection in background-only areas",
          "vague or underspecified region descriptions",
          "confusion between background texture and camouflaged objects",
          "claiming absence based on assumed rather than visually supported empty regions"
        ]
      },
      {
        "claim_id": "occlusion_robustness",
        "name": "Partially Occluded Object Recognition",
        "capability": "partial_visibility_handling",
        "target_failure_id": "FR_OCCLUSION_SENSITIVITY",
        "claim_template": "The partially visible object in the image is identifiable as a [OBJECT_IDENTITY].",
        "slots": {
          "OBJECT_IDENTITY": {
            "type": "object_category",
            "selection_criteria": "Select the most salient partially occluded object that retains sufficient visual cues for identification"
          }
        },
        "baseline_instructions": [
          "Identify objects that are partially occluded, truncated, or only partially visible.",
          "Select the most salient partially visible object that still retains sufficient visual cues for recognition.",
          "If all objects are fully visible, all objects are too heavily occluded to identify, or no partial occlusion exists, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "All objects in the image are fully visible with no occlusion",
          "All partially visible objects are too heavily occluded to retain any recognizable features",
          "No objects with partial visibility exist in the image"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "refusing to identify partially visible objects",
          "misidentifying occluded objects",
          "ignoring valid partial objects",
          "over-reliance on complete visibility"
        ]
      },
      {
        "claim_id": "orientation_facing_direction",
        "name": "Object Orientation Recognition",
        "capability": "directional_orientation_reasoning",
        "target_failure_id": "FR_OBJECT_ORIENTATION_ERROR",
        "claim_template": "The [OBJECT] is facing [VIEW_DIRECTION] in the image frame, and it is facing [OBJECT_DIRECTION] relative to itself.",
        "slots": {
          "OBJECT": {
            "type": "object_instance",
            "selection_criteria": "Select the most salient object that has a clearly perceivable facing direction in the current view (e.g., people, animals, vehicles, arrows)."
          },
          "VIEW_DIRECTION": {
            "type": "categorical_value",
            "values": [
              "left",
              "right",
              "up",
              "down",
              "top-left",
              "top-right",
              "bottom-left",
              "bottom-right",
              "directly facing the viewer",
              "exactly opposite the viewer"
            ],
            "selection_criteria": "Determine the facing direction of the selected object relative to the displayed image and viewer perspective, after any image rotation. Use 'directly facing the viewer' if the object is looking straight at the camera, and 'exactly opposite the viewer' if the object is facing exactly the opposite direction of the camera, not merely not looking at it."
          },
          "OBJECT_DIRECTION": {
            "type": "categorical_value",
            "values": [
              "forward",
              "backward",
              "upward",
              "downward",
              "head raised",
              "head lowered",
              "leftward",
              "rightward"
            ],
            "selection_criteria": "Determine the facing direction of the object relative to its own canonical orientation, ignoring image rotation or camera viewpoint."
          }
        },
        "prefill_slots": ["OBJECT"],
        "baseline_instructions": [
          "Determine the VIEW_DIRECTION of the OBJECT using the displayed image and viewer perspective, after any image rotation.",
          "Determine the OBJECT_DIRECTION of the OBJECT relative to its own canonical orientation, independent of image rotation or camera viewpoint.",
          "If only orientation-neutral objects exist (e.g., spheres, boxes with no discernible front), or orientation is completely ambiguous, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "All objects in the image are orientation-neutral (no inherent facing direction).",
          "Object orientation is completely ambiguous or cannot be determined from visible cues.",
          "No objects with directional properties exist in the image."
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "left-right confusion",
          "difficulty with small or occluded objects",
          "confusion with overlapping objects",
          "failure in fine-grained directional discrimination",
          "reference frame confusion between image/view perspective and object-centric orientation"
        ]
      },
      {
        "claim_id": "geographic_place_recognition",
        "name": "Geographic Location Identification",
        "capability": "map_based_place_recognition",
        "target_failure_id": "FR_PLACE_RECOGNITION_ERROR",
        "claim_template": "The highlighted region in the map represents [GEOGRAPHIC_LOCATION].",
        "slots": {
          "GEOGRAPHIC_LOCATION": {
            "type": "abstract_concept",
            "selection_criteria": "Infer the real-world geographic location (country, state, region, city) from the highlighted region and surrounding map context"
          }
        },
        "baseline_instructions": [
          "Determine if the image is a geographic map with a visually highlighted or distinguished region.",
          "Use shape, surrounding context, and any visual cues to infer the geographic location.",
          "If not a map, no highlighted region exists, or insufficient geographic cues are available for identification, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image is not a geographic map representation",
          "No region is visually highlighted or distinguished from the background",
          "Insufficient geographic cues exist to support location inference (too abstract or schematic)",
          "Map is purely fictional or non-geographic"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "misidentifying similar-shaped regions",
          "requiring external knowledge beyond visual cues",
          "confusion due to map distortion",
          "failure with minimal textual labels"
        ]
      },
      {
        "claim_id": "image_text_alignment",
        "name": "Image-to-Text Description Alignment",
        "capability": "visual_content_captioning",
        "target_failure_id": "FR_BASIC_IMAGE_TEXT_ALIGNMENT",
        "claim_template": "The image depicts [SCENE_DESCRIPTION].",
        "slots": {
          "SCENE_DESCRIPTION": {
            "type": "natural_language_text",
            "selection_criteria": "Generate a natural language description capturing the main visually perceivable content (objects, scenes, activities, or compositions)"
          }
        },
        "baseline_instructions": [
          "Generate a description that accurately reflects the main visually perceivable content in the image.",
          "Focus on objects, scenes, activities, or compositional elements that are directly observable.",
          "If the image is severely degraded, purely abstract with no recognizable content, or contains only noise, return NOT_RELATED."
        ],
        "not_related_conditions": [
          "Image is severely degraded, too blurry, or noisy to discern any content",
          "Image is purely abstract with no recognizable objects, scenes, or activities",
          "No visually perceivable content exists to describe"
        ],
        "expected_outputs": ["TRUE", "FALSE", "NOT_RELATED"],
        "common_failure_modes": [
          "omitting visible objects or activities",
          "misrepresenting scene content",
          "relying on external context not in the image",
          "overly generic or hallucinated descriptions"
        ]
      }
    ],
  
    "global_guidelines": {
      "slot_instantiation_principle": "The baseline model independently selects the most appropriate and salient elements from the image for each slot based on the selection_criteria. The goal is to maximize claim relevance and testability.",
      "not_related_usage": "Return NOT_RELATED only when the image fundamentally lacks the necessary visual properties to instantiate a meaningful claim for the given schema. This ensures claims are only generated when they can be meaningfully evaluated.",
      "integer_values": "All COUNT or numeric slots must return exact integer values, not ranges or approximations.",
      "percentage_values": "All percentage_value slots should return a numeric percentage in 0–100% (optionally with one decimal place), e.g., '37%'. Do not use bucketed categories.",
      "evaluation_principle": "Claims should be evaluable as TRUE or FALSE based solely on visual content, without requiring external context beyond common knowledge."
    }
  }